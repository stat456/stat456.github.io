




#### Week One: Course Introduction

##### Weekly Materials


##### Class Overview 

- Thursday January 19: [Course Overview and Introductory Activity](https://github.com/stat456/Activities/blob/main/Activity1.pdf) ([PDF Notes](https://github.com/stat456/Notes/blob/main/Lecture1.pdf)),  ([RMD Notes](https://github.com/stat456/Notes/blob/main/Lecture1.Rmd))

---

#### Week Two: Bayesian Analysis and Statistical Models

##### Weekly Materials

- [Homework 0, due Tuesday January 24th](https://github.com/stat456/HW/raw/main/HW0.pdf) ([RMD Source Code](https://raw.githubusercontent.com/stat456/HW/main/HW0.Rmd)) (Submit to Gradescope)
- Video Lectures: [Week 2 Module](https://montana.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=cbbde6cb-20c6-4afd-8532-af8a00108897) ([PDF Notes](https://github.com/stat456/Notes/blob/main/Week2.pdf)),  ([RMD Notes](https://github.com/stat456/Notes/blob/main/Week2.Rmd)) (Submit your notes to D2L)

- Course Reading: Ch 1 & Ch 2   
 

##### Class Overview

- Tuesday January 24: [Activity 2: Priors & Reallocation of Credibility](https://github.com/stat456/Activities/blob/main/Activity2.pdf) ([RMD Source](https://github.com/stat456/Activities/blob/main/Activity2.Rmd))

- Thursday January 26: 
---

#### Week Three: Probability and Monte Carlo Procedures in R 

##### Weekly Materials

- Video Lectures:
- Course Reading: Ch 4


##### Class Overview

- Tuesday January 31: 

- Thursday February 2: 

---

#### Week Four: Conditional Probability and Bayes Rule

##### Weekly Materials

- Video Lectures:
- Course Reading: Ch 5


##### Class Overview

- Tuesday February 7: 

- Thursday February 9: 

---

#### Week Five: Binomial Probability, Exact Analysis

##### Weekly Materials

- Video Lectures:
- Course Reading: Ch 6


##### Class Overview

- Tuesday February 14: 

- Thursday February 16:

---

#### Week Six: Markov Chain Monte Carlo

##### Weekly Materials

- Video Lectures:
- Course Reading: Ch 7  

##### Class Overview

- Tuesday February 21: 

- Thursday February 23: 


---

#### Week Seven: Normal Distribution

##### Weekly Materials

- Video Lectures:
- Course Reading: Ch 16


##### Class Overview

- Tuesday February 28:

- Thursday March 2:

---

#### Week Eight: Exam Week

##### Weekly Materials

- Video Lectures:
- Suggested Reading:    


##### Class Overview

- Tuesday March 7: 

- Thursday March 9:

---

#### Week Nine: Spring Break

- Tuesday March 14:  __spring break__

- Thursday March 16: __spring break__

---

#### Week Ten: Bayesian T-Tests

##### Weekly Materials

- Video Lectures:
- Suggested Reading:    


##### Class Overview

- Tuesday March 21: 

- Thursday March 23:


---

#### Week Eleven: Bayesian Regression

##### Weekly Materials


- Suggested Reading: 

- Video Lectures:
- Suggested Reading:    

##### Class Overview

- Tuesday March 28: 

- Thursday March 30: 

---

#### Week Twelve: Bayesian Generalized Linear Models

##### Weekly Materials

- Video Lectures:
- Suggested Reading:    

##### Class Overview

- Tuesday April 4: 

- Thursday April 6:

---

#### Week Thirteen: Bayesian Hierarchical Models

##### Weekly Materials

- Video Lectures:
- Suggested Reading:    


##### Class Overview

- Tuesday April 11: 

- Thursday April 13: 
  
---

#### Week Fourteen: 

##### Weekly Materials

- Video Lectures:
- Suggested Reading:    


##### Class Overview

- Tuesday April 18: 

- Thursday April 20:

---

#### Week Fifteen: 

##### Weekly Materials

- Video Lectures:
- Suggested Reading:    

##### Class Overview

- Tuesday April 25:

- Thursday April 27:

---

#### Week Sixteen: 

##### Weekly Materials

- Video Lectures:
- Suggested Reading:    


##### Class Overview

- Tuesday May 2: 

- Thursday May 4: 

---

#### Week Seventeen: Finals Week

- Tuesday May 9, 8 - 9:50:



#### Course Description

This course will introduce the basic ideas of Bayesian statistics and provide a contrast with techniques for classical inference. The course focuses on both the philosophical foundations and practical implementation of Bayesian methods.

### Learning Outcomes:

At the completion of this course, students will be able to:

1. Describe fundamental differences between Bayesian and classical inference,
2. Select models and priors, write likelihoods, write full probability models and derive posterior distributions, and critically assess/examine model and prior assumptions,
3. Use computer code, including R, STAN, JAGS or Nimble, to sample from posterior distributions, and diagnose non-convergence of samplers, and
4. Make inferences from posterior distributions and learn how to perform posterior predictive assessments of models.



### Prerequisites

- MATH 172 (Calculus II) or equivalent and STAT 217 or STAT 411 and STAT 408. 


### Textbooks

- Doing Bayesian Data Analysis, Second Edition, by John Kruschke 

### Office Hours

- Thur 8:30 - 9:15, Tues 10:45 - 12, 2 - 3

## Course Policies

### Course Structure

This course will be taught from a flipped perspective. Most lecture material will be presented through weekly modules consisting of video lectures. This will enable the use of class time for computational exercises, group work, and practice problems. 

### Assessment and schedule of assignments

- **10%** of your grade will be determined by note taking associated with the online lectures. Notes for each module will be due on Tuesday prior to the start of class.

- **15%** of your grade will be determined by labs, which will be completed in groups during class on Thursdays.

- **15%** of your grade will be determined by regular homework. Students are allowed and encouraged to work with classmates on homework assignments, but each student is required to submit their own homework.

- **20%** of your grade will be determined by a course project, which will be completed over the course of the semester. Can be a group project for groups of up to size 2.

- **40%** of your grade will be determined by two required tests. The midterm exam will be roughly 7 weeks into the semester and the final exam will be held at the start of the last scheduled week of classes. Both exams will have in class and take home components.


### Collaboration
University policy states that, unless otherwise specified, students may not collaborate on graded material. Any exceptions to this policy will be stated explicitly for individual assignments. If you have any questions about the limits of collaboration, you are expected to ask for clarification.

In this class students are encouraged to collaborate on labs, homework, and projects, but exams should be completed without collaboration.

###  Academic Misconduct
Section 420 of the Student Conduct Code describes academic misconduct as including but not limited to plagiarism, cheating, multiple submissions, or facilitating othersâ€™ misconduct. Possible sanctions for academic misconduct range from an oral reprimand to expulsion from the university.

### Disabilities Policy

Federal law mandates the provision of services at the university-level to qualified students with disabilities. If you have a documented disability for which you are or may be requesting an accommodation(s), you are encouraged to contact the Office of Disability Services as soon as possible.


## Major Topics:

1. __Intro to Statistical Inference:__ Using relevant datasets, we will define and discuss credibility, models, and parameters.

2. __Probability & Bayes Rule:__ This course will provide a quick overview of statistical distributions and probability topics necessary for Bayesian inference.

3. __One Parameter Models (exact inference):__ An overview of binomial and Poisson models with a single parameter. Conjugate priors will be used for exact posterior inference.

4. __Markov Chain Monte Carlo (MCMC):__ MCMC will be introduced to approximate the posterior distribution. Code will be written in R with some combination of Stan, JAGS, or Nimble.

5. __One Parameter Models:__ MCMC will be applied to one parameter models.

6. __Two Parameter Models:__ MCMC will be used to estimate parameters from probability distributions with multiple parameters, such as the normal distribution and a negative binomial distribution.

7. __Linear Models:__ Bayesian techniques and MCMC will be used for problems related to two sample estimation and testing (traditional t-test setting) as well as regression models, more generally.

8. __Generalized Linear Models:__ Bayesian techniques and MCMC will be used to estimate relationships between predictor variables and binary or count responses using generalized linear models. The course will include binary and count regression.

9. __Bayesian Hierarchical Models:__ Hierarchical models permit partial pooling, or information sharing across groups. The course will introduce hierarchical models - traditionally referred as mixed models - in a mean-only setting as well as in the framework of generalized linear models.

---
